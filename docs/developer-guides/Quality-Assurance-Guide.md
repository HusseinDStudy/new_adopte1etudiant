# Testing Guide

## Overview

This project maintains an automated test suite. Coverage reports are generated by CI and stored as artifacts; for current metrics see the `apps/api/coverage/` directory or the CI job artifacts.

All tests use **Vitest** as the testing framework with **Supertest** for API integration testing.

## Testing Philosophy and Strategy

### Quality First Approach
We believe that **quality is everyone's responsibility** and that automated testing is essential for:
- **Rapid development cycles** with confidence
- **Regression prevention** during refactoring
- **Documentation** of expected behavior
- **Improved code design** through testability requirements

### Pyramid Strategy
Our testing strategy follows the testing pyramid principle:

```
                    / \
                   /   \
                  / E2E \
                 /_______\
                /         \
               /Integration\
              /_____________\
             /               \
            /       Unit      \
           /___________________\
```

1. **Unit Tests (Foundation)**: Fast, isolated tests for business logic
2. **Integration Tests (Majority)**: API endpoint testing with database
3. **End-to-End Tests (Selective)**: Critical user workflows

## Test Architecture

### Test Categories

1. **Unit Tests** - Individual controller and middleware functions
2. **Integration Tests** - Full API endpoint testing with database
3. **End-to-End Tests** - Complete user workflows
4. **Security Tests** - Authentication, authorization, and security vulnerabilities
5. **Performance Tests** - Load testing and stress testing
6. **Contract Tests** - API contract validation

### Test File Structure

```
src/__tests__/
├── helpers/
│   ├── test-app.ts          # Test application setup
│   └── test-setup.ts        # Database helpers and test utilities
├── auth.test.ts             # Authentication and authorization
├── application.test.ts      # Job application management
├── adoptionRequest.test.ts  # Student adoption requests
├── message.test.ts          # Messaging and conversations
├── company.test.ts          # Company management
├── student.test.ts          # Student management
├── offer.test.ts            # Job offer management
├── skill.test.ts            # Skills management
├── profile.test.ts          # User profile management
├── twoFactorAuth.test.ts    # Two-factor authentication
├── oauth.test.ts            # OAuth integration
├── security.test.ts         # Security testing
├── performance.test.ts      # Performance and load testing
├── e2e-workflows.test.ts    # End-to-end user workflows
├── api-contract.test.ts     # API contract validation
└── optionalAuthMiddleware.test.ts # Optional auth middleware
```

## Running Tests

Before running the test suite, a PostgreSQL instance must be available. You can start the local development database using:

```bash
docker compose -f docker-compose.db.yml up -d
```

Ensure the `DATABASE_URL` environment variable matches the connection string in `.env.example` before executing `npm test`.


### All Tests
```bash
npm test
```

### Specific Test File
```bash
npm test --workspace=apps/api -- src/__tests__/auth.test.ts
```

### With Coverage Report
```bash
npm test -- --coverage
```

### Watch Mode (Development)
```bash
npm run test:watch
```

### Debug Mode
```bash
npm test -- --reporter=verbose
```

## Test Setup and Helpers

### Database Management

The test suite uses helper functions for consistent database management:

```typescript
// Clean database before each test
await cleanupDatabase();

// Create test data
const company = await createTestCompany(app);
const student = await createTestStudent(app);
const skills = await createTestSkills(['React', 'Node.js']);
```

### Test Application Setup

Each test file uses a standardized application setup:

```typescript
describe('Test Suite', () => {
  let app: FastifyInstance;

  beforeAll(async () => {
    app = await buildTestApp();
  });

  afterAll(async () => {
    await app.close();
  });

  beforeEach(async () => {
    await cleanupDatabase();
    // Setup test data
  });

  afterEach(async () => {
    await cleanupDatabase();
  });
});
```

## Coverage Goals and Achievements

### Coverage Targets
- **Statement Coverage**: ≥80%
- **Branch Coverage**: ≥80%
- **Function Coverage**: ≥90%

### Controller-Specific Coverage

| Controller | Statement | Branch | Functions | Status |
|------------|-----------|---------|-----------|---------|
| applicationController | 93.54% | 86.66% | 100% | ✅ Excellent |
| adoptionRequestController | 93.39% | 75.86% | 100% | ✅ Good |
| messageController | 91.46% | 76.66% | 100% | ✅ Good |
| authController | 90.07% | 80.55% | 100% | ✅ Good |
| companyController | 88.46% | 50% | 100% | ⚠️ Limited branching |
| skillController | 88.46% | 50% | 100% | ⚠️ Limited branching |

## Testing Best Practices

### 1. Test Structure
Follow the **Arrange-Act-Assert** pattern:

```typescript
it('should create a new user', async () => {
  // Arrange
  const userData = {
    email: 'test@example.com',
    password: 'password123',
    role: 'STUDENT'
  };

  // Act
  const response = await supertest(app.server)
    .post('/api/auth/register')
    .send(userData);

  // Assert
  expect(response.status).toBe(201);
  expect(response.body.email).toBe(userData.email);
});
```

### 2. Database Isolation
Each test should be isolated and not depend on other tests:

```typescript
beforeEach(async () => {
  await cleanupDatabase();
  // Create fresh test data for this test
});
```

### 3. Authentication Testing
Test both authenticated and unauthenticated scenarios:

```typescript
// Test authenticated access
const response = await supertest(app.server)
  .get('/api/profile')
  .set('Cookie', `token=${authToken}`);

// Test unauthenticated access
const unauthResponse = await supertest(app.server)
  .get('/api/profile');
expect(unauthResponse.status).toBe(401);
```

### 4. Error Case Testing
Always test error scenarios:

```typescript
// Test validation errors
const response = await supertest(app.server)
  .post('/api/auth/register')
  .send({ email: 'invalid-email' });
expect(response.status).toBe(400);

// Test resource not found
const response = await supertest(app.server)
  .get('/api/offers/nonexistent-id');
expect(response.status).toBe(404);
```

### 5. Edge Case Testing
Test boundary conditions and edge cases:

```typescript
// Empty arrays
expect(response.body).toBeInstanceOf(Array);
expect(response.body.length).toBe(0);

// Large payloads
const largeDescription = 'x'.repeat(10000);
// Test limits and validation

// Special characters and encoding
const specialChars = 'Test with émojis 🚀 and special chars';
```

## Comprehensive Test Categories

### Authentication Tests (`auth.test.ts`)
- User registration (student/company)
- Login/logout flows
- Password validation
- OAuth integration (Google)
- Two-factor authentication
- Session management
- Token validation
- Account linking

### Application Tests (`application.test.ts`)
- Create job applications
- Update application status
- List applications (student/company views)
- Conversation creation on status changes
- Permission validation
- Duplicate application prevention

### Adoption Request Tests (`adoptionRequest.test.ts`)
- Create adoption requests
- Update request status (accept/reject)
- List sent/received requests
- Conversation integration
- Company profile requirements
- Duplicate request prevention

### Message Tests (`message.test.ts`)
- Create conversations
- Send/receive messages
- List conversations with proper ordering
- Access control validation
- Rejected conversation handling
- Empty conversation scenarios

### Security Tests (`security.test.ts`)
- SQL injection prevention
- XSS protection
- CSRF protection
- Rate limiting
- Session security
- Concurrent login protection

### Performance Tests (`performance.test.ts`)
- Load testing with multiple concurrent users
- Database query optimization
- Response time benchmarking
- Memory usage monitoring
- Stress testing under high load

## Test Data Management

### Faker Integration
The test suite uses `@faker-js/faker` for generating realistic test data:

```typescript
const userData = {
  email: faker.internet.email(),
  firstName: faker.person.firstName(),
  lastName: faker.person.lastName(),
  password: faker.internet.password()
};
```

### Test Helpers
Standardized helpers for common operations:

```typescript
// Create test company with profile
const company = await createTestCompany(app, {
  name: 'Test Company',
  contactEmail: 'test@company.com'
});

// Create test student with profile
const student = await createTestStudent(app, {
  firstName: 'John',
  lastName: 'Doe'
});

// Create predefined skills
const skills = await createTestSkills(['React', 'Node.js', 'Python']);
```

## Debugging Failed Tests

### Common Issues and Solutions

1. **Database State Issues**
   ```bash
   # Ensure clean database state
   await cleanupDatabase();
   ```

2. **Authentication Token Issues**
   ```typescript
   // Verify token extraction
   const cookie = response.headers['set-cookie'][0];
   const token = cookie.split(';')[0].replace('token=', '');
   ```

3. **Timing Issues**
   ```typescript
   // Add delays for timestamp-dependent tests
   await new Promise(resolve => setTimeout(resolve, 100));
   ```

4. **Foreign Key Constraint Violations**
   ```typescript
   // Follow proper deletion order
   await prisma.message.deleteMany();
   await prisma.conversation.deleteMany();
   await prisma.application.deleteMany();
   // ... continue in dependency order
   ```

### Debugging Commands

```bash
# Run specific test with verbose output
npm test --workspace=apps/api -- src/__tests__/auth.test.ts --reporter=verbose

# Run single test case
npm test --workspace=apps/api -- src/__tests__/auth.test.ts -t "should register a new user"

# Debug with console output
npm test --workspace=apps/api -- --reporter=verbose --silent=false
```

## Test Coverage Analysis

### Reading Coverage Reports

The coverage report shows:
- **Statements**: Lines of code executed
- **Branches**: Conditional paths tested
- **Functions**: Functions called during tests
- **Lines**: Physical lines covered

### Improving Coverage

1. **Identify Uncovered Code**
   ```bash
   npm test -- --coverage --reporter=verbose
   ```

2. **Add Missing Test Cases**
   - Error handling paths
   - Edge cases and boundary conditions
   - Alternative code paths
   - Exception scenarios

3. **Focus on Low Coverage Areas**
   - Controllers with <80% branch coverage
   - Complex conditional logic
   - Error handling code

## Continuous Integration

### GitHub Actions Integration
Tests run automatically on:
- Pull request creation
- Push to main branch
- Scheduled daily runs

### Coverage Thresholds
CI fails if coverage drops below:
- 70% statement coverage
- 70% function coverage
- 65% branch coverage

## Future Improvements

### Planned Enhancements
1. **Visual Regression Testing** - UI component testing
2. **API Performance Benchmarking** - Automated performance monitoring
3. **Database Migration Testing** - Schema change validation
4. **Security Vulnerability Scanning** - Automated security testing
5. **Cross-browser Testing** - Frontend compatibility testing

### Coverage Goals
- **Target**: 90%+ statement coverage
- **Stretch Goal**: 85%+ branch coverage
- **Maintain**: 100% function coverage

## Contributing to Tests

### Adding New Tests
1. Follow existing test file patterns
2. Include both success and error cases
3. Test authentication requirements
4. Add edge case scenarios
5. Maintain database isolation

### Test Review Checklist
- [ ] Tests are isolated and don't depend on each other
- [ ] Both positive and negative cases are covered
- [ ] Authentication/authorization is tested
- [ ] Edge cases and error conditions are included
- [ ] Database cleanup is properly handled
- [ ] Test names are descriptive and clear

## Conclusion

The test suite provides comprehensive coverage of the application's functionality, ensuring reliability and maintainability. With 302 tests achieving high coverage standards, the codebase is well-protected against regressions and provides confidence for ongoing development.

Regular test maintenance and continuous improvement of coverage ensure the application remains robust and reliable as it evolves. 

## API Testing Details

This section covers comprehensive testing strategies for the Adopte1Etudiant API, including unit tests, integration tests, and API documentation validation.

### Test Pyramid for API

```
    /\
   /  \     E2E Tests (Few)
  /____\    
 /      \   Integration Tests (Some)
/__________\ Unit Tests (Many)
```

1. **Unit Tests**: Test individual functions and components
2. **Integration Tests**: Test API endpoints and database interactions
3. **End-to-End Tests**: Test complete user workflows
4. **Documentation Tests**: Validate API docs match implementation

### Quick Start for API Testing

#### Running All API-related Tests

```bash
# Run all tests
npm run test

# Run API-specific tests
npm run test --workspace=apps/api

# Run tests in watch mode
npm run test:watch --workspace=apps/api

# Run tests with coverage
npm run test:coverage --workspace=apps/api
```

#### API Documentation Validation

```bash
# Validate API documentation against implementation
npm run docs:validate

# Generate and validate documentation
npm run docs:generate && npm run docs:validate
```

### API Test Configuration

#### Vitest Configuration

The API uses Vitest for testing. Configuration is in `apps/api/vitest.config.ts`:

```typescript
import { defineConfig } from 'vitest/config';

export default defineConfig({
  test: {
    globals: true,
    environment: 'node',
    setupFiles: ['./src/__tests__/setup.ts'],
    coverage: {
      provider: 'v8',
      reporter: ['text', 'json', 'html'],
      exclude: [
        'node_modules/',
        'dist/',
        '**/*.d.ts',
        'prisma/',
        'scripts/'
      ]
    }
  }
});
```

#### Test Environment Setup

Tests use a separate test database and environment:

```typescript
// src/__tests__/setup.ts
import { beforeAll, afterAll, beforeEach } from 'vitest';
import { prisma } from 'db-postgres';

beforeAll(async () => {
  // Setup test database
  await prisma.$connect();
});

afterAll(async () => {
  // Cleanup
  await prisma.$disconnect();
});

beforeEach(async () => {
  // Clean database before each test
  await cleanDatabase();
});
```

### Unit Testing API Components

#### Testing Controllers

```typescript
// src/__tests__/controllers/authController.test.ts
import { describe, it, expect, vi } from 'vitest';
import { registerUser } from '../controllers/authController.js';
import { createTestApp } from '../helpers/test-app.js';

describe('Auth Controller', () => {
  it('should register a new student', async () => {
    const app = await createTestApp();
    
    const response = await app.inject({
      method: 'POST',
      url: '/api/auth/register',
      payload: {
        role: 'STUDENT',
        email: 'test@example.com',
        password: 'password123',
        firstName: 'John',
        lastName: 'Doe'
      }
    });
    
    expect(response.statusCode).toBe(201);
    expect(response.json()).toMatchObject({
      email: 'test@example.com',
      role: 'STUDENT'
    });
  });
  
  it('should reject invalid email format', async () => {
    const app = await createTestApp();
    
    const response = await app.inject({
      method: 'POST',
      url: '/api/auth/register',
      payload: {
        role: 'STUDENT',
        email: 'invalid-email',
        password: 'password123',
        firstName: 'John',
        lastName: 'Doe'
      }
    });
    
    expect(response.statusCode).toBe(400);
  });
});
```

#### Testing Services

```typescript
// src/__tests__/services/userService.test.ts
import { describe, it, expect, beforeEach } from 'vitest';
import { createUser, getUserById } from '../services/userService.js';
import { cleanDatabase } from '../helpers/test-helpers.js';

describe('User Service', () => {
  beforeEach(async () => {
    await cleanDatabase();
  });
  
  it('should create a new user', async () => {
    const userData = {
      email: 'test@example.com',
      password: 'hashedPassword',
      role: 'STUDENT'
    };
    
    const user = await createUser(userData);
    
    expect(user).toMatchObject({
      email: 'test@example.com',
      role: 'STUDENT'
    });
    expect(user.id).toBeDefined();
  });
  
  it('should retrieve user by ID', async () => {
    const userData = {
      email: 'test@example.com',
      password: 'hashedPassword',
      role: 'STUDENT'
    };
    
    const createdUser = await createUser(userData);
    const retrievedUser = await getUserById(createdUser.id);
    
    expect(retrievedUser).toMatchObject(createdUser);
  });
});
```

### Integration Testing API Endpoints

#### Testing API Endpoints

```typescript
// src/__tests__/integration/offers.test.ts
import { describe, it, expect, beforeEach } from 'vitest';
import { createTestApp } from '../helpers/test-app.js';
import { createTestUser, loginTestUser } from '../helpers/auth-helpers.js';

describe('Offers API', () => {
  let app;
  let authCookie;
  
  beforeEach(async () => {
    app = await createTestApp();
    
    // Create and login test company
    const company = await createTestUser('COMPANY');
    authCookie = await loginTestUser(app, company);
  });
  
  it('should create a new offer', async () => {
    const offerData = {
      title: 'Software Engineer Intern',
      description: 'Great opportunity for students',
      location: 'Paris',
      duration: '6 months',
      skills: ['JavaScript', 'React']
    };
    
    const response = await app.inject({
      method: 'POST',
      url: '/api/offers',
      headers: {
        cookie: authCookie
      },
      payload: offerData
    });
    
    expect(response.statusCode).toBe(201);
  });
});
```

#### Testing Authentication Flow

```typescript
// src/__tests__/integration/auth-flow.test.ts
import { describe, it, expect } from 'vitest';
import { createTestApp } from '../helpers/test-app.js';

describe('Authentication Flow', () => {
  it('should complete full auth flow', async () => {
    const app = await createTestApp();
    
    // 1. Register
    const registerResponse = await app.inject({
      method: 'POST',
      url: '/api/auth/register',
      payload: {
        role: 'STUDENT',
        email: 'flow-test@example.com',
        password: 'password123',
        firstName: 'Flow',
        lastName: 'Test'
      }
    });
    
    expect(registerResponse.statusCode).toBe(201);
    
    // 2. Login
    const loginResponse = await app.inject({
      method: 'POST',
      url: '/api/auth/login',
      payload: {
        email: 'flow-test@example.com',
        password: 'password123'
      }
    });
    
    expect(loginResponse.statusCode).toBe(200);
    const authCookie = loginResponse.headers['set-cookie'];
    
    // 3. Access protected endpoint
    const meResponse = await app.inject({
      method: 'GET',
      url: '/api/auth/me',
      headers: {
        cookie: authCookie
      }
    });
    
    expect(meResponse.statusCode).toBe(200);
    expect(meResponse.json()).toMatchObject({
      email: 'flow-test@example.com',
      role: 'STUDENT'
    });
    
    // 4. Logout
    const logoutResponse = await app.inject({
      method: 'POST',
      url: '/api/auth/logout',
      headers: {
        cookie: authCookie
      }
    });
    
    expect(logoutResponse.statusCode).toBe(200);
  });
});
```

### Test Helpers for API

#### Database Helpers

```typescript
// src/__tests__/helpers/database-helpers.ts
import { prisma } from 'db-postgres';

export async function cleanDatabase() {
  // Clean in reverse order of dependencies
  await prisma.message.deleteMany();
  await prisma.conversation.deleteMany();
  await prisma.application.deleteMany();
  await prisma.adoptionRequest.deleteMany();
  await prisma.offer.deleteMany();
  await prisma.studentProfile.deleteMany();
  await prisma.companyProfile.deleteMany();
  await prisma.user.deleteMany();
  await prisma.skill.deleteMany();
}

export async function seedTestData() {
  // Create test skills
  await prisma.skill.createMany({
    data: [
      { name: 'JavaScript', category: 'Programming' },
      { name: 'React', category: 'Frontend' },
      { name: 'Node.js', category: 'Backend' }
    ]
  });
}
```

#### Authentication Helpers

```typescript
// src/__tests__/helpers/auth-helpers.ts
import bcrypt from 'bcryptjs';
import { prisma } from 'db-postgres';

export async function createTestUser(role = 'STUDENT', overrides = {}) {
  const baseData = {
    email: `test-${Date.now()}@example.com`,
    password: await bcrypt.hash('password123', 10),
    role,
    ...overrides
  };
  
  const user = await prisma.user.create({
    data: baseData
  });
  
  // Create profile based on role
  if (role === 'STUDENT') {
    await prisma.studentProfile.create({
      data: {
        userId: user.id,
        firstName: 'Test',
        lastName: 'Student',
        school: 'Test University',
        degree: 'Computer Science'
      }
    });
  } else if (role === 'COMPANY') {
    await prisma.companyProfile.create({
      data: {
        userId: user.id,
        name: 'Test Company',
        contactEmail: user.email,
        sector: 'Technology'
      }
    });
  }
  
  return user;
}

export async function loginTestUser(app, user) {
  const response = await app.inject({
    method: 'POST',
    url: '/api/auth/login',
    payload: {
      email: user.email,
      password: 'password123'
    }
  });
  
  return response.headers['set-cookie'];
}
```

### API Test Coverage

#### Coverage Reports

```bash
# Generate coverage report
npm run test:coverage --workspace=apps/api

# View coverage in browser
open apps/api/coverage/index.html
```

#### Coverage Targets

- **Overall**: > 80%
- **Controllers**: > 90%
- **Services**: > 95%
- **Utilities**: > 90%

#### Excluding Files from Coverage

```typescript
// vitest.config.ts
export default defineConfig({
  test: {
    coverage: {
      exclude: [
        'node_modules/',
        'dist/',
        '**/*.d.ts',
        'prisma/',
        'scripts/',
        'src/__tests__/',
        'src/types/',
        'src/config/swagger.ts' // Large config files
      ]
    }
  }
});
```

### API Documentation Testing

#### Automated Validation

```bash
# Validate API docs match implementation
npm run docs:validate

# This script:
# 1. Checks API health
# 2. Fetches OpenAPI spec
# 3. Tests public endpoints
# 4. Tests authentication flow
# 5. Validates response structures
# 6. Checks documentation files exist
```

#### Manual Testing with Swagger UI

1. Start the API: `npm run dev --workspace=apps/api`
2. Open Swagger UI: [/docs](/docs)
3. Test endpoints using "Try it out" buttons
4. Verify request/response examples match documentation

### Error Testing for API

#### Testing Error Scenarios

```typescript
describe('Error Handling', () => {
  it('should handle validation errors', async () => {
    const response = await app.inject({
      method: 'POST',
      url: '/api/auth/register',
      payload: {
        role: 'INVALID_ROLE',
        email: 'invalid-email'
      }
    });
    
    expect(response.statusCode).toBe(400);
    expect(response.json()).toHaveProperty('message');
  });
  
  it('should handle unauthorized access', async () => {
    const response = await app.inject({
      method: 'GET',
      url: '/api/auth/me'
      // No auth cookie
    });
    
    expect(response.statusCode).toBe(401);
  });
  
  it('should handle rate limiting', async () => {
    // Make many requests quickly
    const promises = Array(100).fill().map(() =>
      app.inject({
        method: 'GET',
        url: '/api/offers'
      })
    );
    
    const responses = await Promise.all(promises);
    const rateLimited = responses.some(r => r.statusCode === 429);
    
    expect(rateLimited).toBe(true);
  });
});
```

### Continuous Integration for API Tests

#### GitHub Actions

```yaml
# .github/workflows/api-tests.yml
name: API Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run database migrations
        run: npm run db:migrate --workspace=apps/api
        env:
          DATABASE_URL: postgresql://postgres:test@localhost:5432/test
      
      - name: Run tests
        run: npm run test --workspace=apps/api
        env:
          DATABASE_URL: postgresql://postgres:test@localhost:5432/test
      
      - name: Validate API documentation
        run: npm run docs:validate
```

### Performance Testing for API

#### Load Testing with Artillery

```yaml
# artillery-config.yml
config:
  target: 'http://localhost:8080'
  phases:
    - duration: 60
      arrivalRate: 10
      name: "Warm up"
    - duration: 120
      arrivalRate: 50
      name: "Load test"

scenarios:
  - name: "API Load Test"
    flow:
      - get:
          url: "/api/offers"
      - get:
          url: "/api/companies"
      - get:
          url: "/api/skills"
```

```bash
# Run load tests
npx artillery run artillery-config.yml
```

### Best Practices for API Testing

1. **Test Isolation**: Each test should be independent
2. **Clean State**: Reset database between tests
3. **Realistic Data**: Use realistic test data
4. **Error Cases**: Test both success and failure scenarios
5. **Performance**: Include performance regression tests
6. **Documentation**: Keep tests well-documented
7. **Maintenance**: Regularly update tests with API changes

### Troubleshooting API Tests

#### Common Issues

1. **Database Connection**: Ensure test database is running
2. **Port Conflicts**: Use different ports for test environment
3. **Async Issues**: Properly handle async operations
4. **Memory Leaks**: Clean up resources after tests
5. **Flaky Tests**: Identify and fix non-deterministic tests

#### Debug Mode

```bash
# Run tests in debug mode
npm run test:debug --workspace=apps/api

# Run specific test file
npm run test -- auth.test.ts --workspace=apps/api
``` 

## Acceptance Testing (Runbook)

### Purpose
Detect functional anomalies and regressions through structured test scenarios and expected results.

### Prerequisites
- API running (see README)
- Local PostgreSQL up (`docker compose -f docker-compose.db.yml up -d`)
- Seed data if needed (`apps/api/prisma/seed.ts`)

### Scenario Template
- ID
- Title
- Preconditions
- Steps
- Expected Result
- Artifacts (tokens, IDs)

### Detailed Test Scenarios

#### 3.1. User Registration and Authentication

#### Scenario 3.1.1: Student Registration Success
*   **Precondition**: User is not registered.
*   **Steps**:
    1. Navigate to the registration page.
    2. Select 'Student' role.
    3. Fill in all required fields with valid data.
    4. Submit the registration form.
*   **Expected Result**: User is successfully registered as a student, redirected to the student dashboard, and receives a confirmation email.

#### Scenario 3.1.2: Company Registration Success
*   **Precondition**: User is not registered.
*   **Steps**:
    1. Navigate to the registration page.
    2. Select 'Company' role.
    3. Fill in all required fields with valid data.
    4. Submit the registration form.
*   **Expected Result**: User is successfully registered as a company, redirected to the company dashboard, and receives a confirmation email.

#### Scenario 3.1.3: User Login Success
*   **Precondition**: User is registered and verified.
*   **Steps**:
    1. Navigate to the login page.
    2. Enter valid credentials (email/password).
    3. Submit the login form.
*   **Expected Result**: User is successfully logged in and redirected to their respective dashboard (student or company).

### 3.2. Profile Management

#### Scenario 3.2.1: Student Profile Creation/Update
*   **Precondition**: Student user is logged in.
*   **Steps**:
    1. Navigate to the student profile editing page.
    2. Fill in/update all relevant profile fields (e.g., skills, experience, education).
    3. Save the changes.
*   **Expected Result**: Student profile is successfully updated and changes are reflected on the profile page.

#### Scenario 3.2.2: Company Profile Creation/Update
*   **Precondition**: Company user is logged in.
*   **Steps**:
    1. Navigate to the company profile editing page.
    2. Fill in/update all relevant profile fields (e.g., company description, industry, location).
    3. Save the changes.
*   **Expected Result**: Company profile is successfully updated and changes are reflected on the company's public page.

### 3.3. Job Offer Management (Company)

#### Scenario 3.3.1: Create New Job Offer
*   **Precondition**: Company user is logged in.
*   **Steps**:
    1. Navigate to the 'Create Offer' page.
    2. Fill in all required offer details (title, description, location, skills, duration, etc.).
    3. Submit the offer form.
*   **Expected Result**: New job offer is successfully created and visible on the company's offers list and public listings.

#### Scenario 3.3.2: Edit Existing Job Offer
*   **Precondition**: Company user is logged in and has existing offers.
*   **Steps**:
    1. Navigate to 'My Offers' page.
    2. Select an existing offer to edit.
    3. Modify relevant offer details.
    4. Save the changes.
*   **Expected Result**: Job offer is successfully updated, and changes are reflected on the public listings.

#### Scenario 3.3.3: Delete Job Offer
*   **Precondition**: Company user is logged in and has existing offers.
*   **Steps**:
    1. Navigate to 'My Offers' page.
    2. Select an existing offer.
    3. Confirm deletion.
*   **Expected Result**: Job offer is successfully deleted and no longer visible on public listings.

### 3.4. Application Management (Student)

#### Scenario 3.4.1: Apply to Job Offer
*   **Precondition**: Student user is logged in and has a complete profile.
*   **Steps**:
    1. Browse job offers.
    2. Select an interesting offer.
    3. Click 'Apply' and confirm application.
*   **Expected Result**: Application is successfully submitted, and the student can see it in 'My Applications'. The company can see it in the offer's applications list.

#### Scenario 3.4.2: View My Applications
*   **Precondition**: Student user is logged in and has submitted applications.
*   **Steps**:
    1. Navigate to 'My Applications' page.
*   **Expected Result**: All submitted applications are listed with their current status.

### 3.5. Real-time Messaging

#### Scenario 3.5.1: Send a Message
*   **Precondition**: Two users (e.g., student and company) have an active conversation.
*   **Steps**:
    1. Open an existing conversation.
    2. Type a message.
    3. Send the message.
*   **Expected Result**: Message is sent successfully and appears in the conversation history for both participants in real-time.

### 3.6. Student Search and Filtering (Company)

#### Scenario 3.6.1: Search for Students by Keyword
*   **Precondition**: Company user is logged in.
*   **Steps**:
    1. Navigate to the 'Students' page.
    2. Enter a keyword (e.g., 'React developer') in the search bar.
    3. Apply search.
*   **Expected Result**: Students whose profiles match the keyword are displayed.

#### Scenario 3.6.2: Filter Students by Skills
*   **Precondition**: Company user is logged in.
*   **Steps**:
    1. Navigate to the 'Students' page.
    2. Select one or more skills from the filter options.
    3. Apply filters.
*   **Expected Result**: Students possessing the selected skills are displayed.

### 3.7. Adoption Request Management

#### Scenario 3.7.1: Company Creates Adoption Request
*   **Precondition**: Company user is logged in.
*   **Steps**:
    1. From a student's profile, initiate an 'Adoption Request'.
    2. Fill in request details (e.g., message, offer).
    3. Send the request.
*   **Expected Result**: Adoption request is sent to the student, and the company can view it in 'Sent Requests'.

#### Scenario 3.7.2: Student Responds to Adoption Request
*   **Precondition**: Student user is logged in and has received an adoption request.
*   **Steps**:
    1. View a received adoption request.
    2. Select to 'Accept' or 'Reject' the request.
    3. Confirm the action.
*   **Expected Result**: Request status is updated, and both student and company are notified of the decision.

### Traceability
- API tests: `apps/api/src/__tests__/*`
- Web a11y tests: `apps/web/src/pages/__tests__/*a11y.test.tsx`
- Monitoring: `monitoring/postman-collection.json`, `monitoring/artillery-config.yml`

### Copy Template
```
ID: R-xxx
Title: ...
Preconditions: ...
Steps: 1) ... 2) ...
Expected: ...
Artifacts: ...
```

## Test Plan

### Document Information
- **Project**: Adopte1Etudiant
- **Version**: 2.0
- **Last Updated**: January 2025
- **Test Environment**: Automated + Manual
- **Total Test Cases**: 302 automated tests

### Test Scope

#### In Scope
- **Authentication & Authorization** (56 test cases)
- **User Management** (Student & Company profiles)
- **Job Application System** (22 test cases)
- **Adoption Request System** (23 test cases) 
- **Messaging System** (31 test cases)
- **Skills Management** (10 test cases)
- **Two-Factor Authentication** (16 test cases)
- **OAuth Integration** (14 test cases)
- **Security Controls** (21 test cases)
- **Performance & Load Testing** (20 test cases)
- **API Contract Validation** (29 test cases)

#### Out of Scope
- Third-party service testing (Google OAuth server)
- Email delivery testing (SMTP server)
- Browser compatibility testing
- Mobile app testing (not yet developed)

### Test Environment

#### Technical Stack
- **Backend**: Node.js + Fastify + TypeScript
- **Database**: PostgreSQL (test instance)
- **Test Framework**: Vitest + Supertest
- **Coverage Tool**: V8 Coverage Provider
- **Data Generation**: @faker-js/faker

#### Environment Setup
- **Isolated test database** with automatic cleanup
- **Mock external services** (email, OAuth)
- **Parallel test execution** for speed
- **Coverage reporting** integrated

### Test Categories

#### 1. Authentication Tests (`auth.test.ts`) - 56 Tests

##### 1.1 User Registration
**Test Cases**: 8 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| AUTH-REG-001 | Register new student with valid data | 201 Created, user profile created |
| AUTH-REG-002 | Register new company with valid data | 201 Created, company profile created |
| AUTH-REG-003 | Register with existing email | 409 Conflict error |
| AUTH-REG-004 | Register with invalid email format | 400 Validation error |
| AUTH-REG-005 | Register with weak password | 400 Validation error |
| AUTH-REG-006 | Register without required fields | 400 Validation error |
| AUTH-REG-007 | Register with malformed request | 400 Bad request |
| AUTH-REG-008 | Register with SQL injection attempt | 400 Validation error |

##### 1.2 User Login
**Test Cases**: 12 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| AUTH-LOG-001 | Login with valid credentials | 200 OK, JWT token set |
| AUTH-LOG-002 | Login with invalid email | 401 Unauthorized |
| AUTH-LOG-003 | Login with invalid password | 401 Unauthorized |
| AUTH-LOG-004 | Login with non-existent user | 401 Unauthorized |
| AUTH-LOG-005 | Login with missing fields | 400 Bad request |
| AUTH-LOG-006 | Login with disabled password | 403 Forbidden |
| AUTH-LOG-007 | Login with OAuth-only account | 401 Unauthorized |
| AUTH-LOG-008 | Login with 2FA enabled | 200 OK, 2FA required |
| AUTH-LOG-009 | Login rate limiting test | 429 Too many requests |
| AUTH-LOG-010 | Login with expired session | 401 Unauthorized |
| AUTH-LOG-011 | Login concurrent sessions | Multiple sessions allowed |
| AUTH-LOG-012 | Login session persistence | Session maintained |

##### 1.3 OAuth Integration
**Test Cases**: 14 tests
**Priority**: High

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| OAUTH-001 | Google OAuth callback success | User authenticated |
| OAUTH-002 | Google OAuth callback with error | Error handled gracefully |
| OAUTH-003 | OAuth account linking | Accounts linked successfully |
| OAUTH-004 | OAuth new user creation | New user created with OAuth |
| OAUTH-005 | OAuth existing user login | Existing user authenticated |
| OAUTH-006 | OAuth profile completion | Profile completion flow |
| OAUTH-007 | OAuth registration flow | Complete OAuth registration |
| OAUTH-008 | OAuth error handling | Errors handled properly |
| OAUTH-009 | OAuth state validation | CSRF protection active |
| OAUTH-010 | OAuth token validation | Tokens validated correctly |
| OAUTH-011 | OAuth user already logged in | Existing session handled |
| OAUTH-012 | OAuth account deletion callback | Account deletion processed |
| OAUTH-013 | OAuth scope validation | Required scopes validated |
| OAUTH-014 | OAuth error edge cases | Various error scenarios |

##### 1.4 Two-Factor Authentication
**Test Cases**: 16 tests
**Priority**: High

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| 2FA-001 | Generate 2FA secret | QR code and secret generated |
| 2FA-002 | Enable 2FA with valid token | 2FA enabled successfully |
| 2FA-003 | Enable 2FA with invalid token | 401 Invalid token |
| 2FA-004 | Enable 2FA when already enabled | 400 Already enabled |
| 2FA-005 | Verify 2FA login with valid token | Login successful |
| 2FA-006 | Verify 2FA login with invalid token | 401 Invalid token |
| 2FA-007 | Verify 2FA with recovery code | Login successful |
| 2FA-008 | Verify 2FA with expired session | 401 Session expired |
| 2FA-009 | Disable 2FA with valid password | 2FA disabled |
| 2FA-010 | Disable 2FA with invalid password | 401 Invalid password |
| 2FA-011 | Generate recovery codes | Codes generated |
| 2FA-012 | Use recovery code once | Code invalidated |
| 2FA-013 | 2FA secret regeneration | New secret generated |
| 2FA-014 | 2FA backup codes validation | Codes validated |
| 2FA-015 | 2FA time window validation | Time-based validation |
| 2FA-016 | 2FA brute force protection | Rate limiting active |

#### 2. Application Management Tests (`application.test.ts`) - 22 Tests

##### 2.1 Create Applications
**Test Cases**: 6 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| APP-CRE-001 | Create application with valid data | 201 Created |
| APP-CRE-002 | Create duplicate application | 409 Conflict |
| APP-CRE-003 | Create without student profile | 403 Forbidden |
| APP-CRE-004 | Create for non-existent offer | 404 Not found |
| APP-CRE-005 | Create without authentication | 401 Unauthorized |
| APP-CRE-006 | Create with invalid offer ID | 400 Bad request |

##### 2.2 Update Application Status
**Test Cases**: 10 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| APP-UPD-001 | Update to HIRED status | Conversation created |
| APP-UPD-002 | Update to INTERVIEW status | Conversation created |
| APP-UPD-003 | Update to REJECTED status | No conversation |
| APP-UPD-004 | Update to SEEN status | No conversation |
| APP-UPD-005 | Update non-existent application | 404 Not found |
| APP-UPD-006 | Update without permission | 403 Forbidden |
| APP-UPD-007 | Update with invalid status | 400 Bad request |
| APP-UPD-008 | Update duplicate conversation | No duplicate created |
| APP-UPD-009 | Update without authentication | 401 Unauthorized |
| APP-UPD-010 | Update with malformed request | 400 Bad request |

##### 2.3 List Applications
**Test Cases**: 6 tests
**Priority**: Medium

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| APP-LST-001 | List student applications | Applications returned |
| APP-LST-002 | List with no applications | Empty array |
| APP-LST-003 | List with proper ordering | Newest first |
| APP-LST-004 | List without authentication | 401 Unauthorized |
| APP-LST-005 | List with conversation data | Conversations included |
| APP-LST-006 | List with offer details | Offer data included |

#### 3. Adoption Request Tests (`adoptionRequest.test.ts`) - 23 Tests

##### 3.1 Create Adoption Requests
**Test Cases**: 8 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| ADR-CRE-001 | Create with valid data | Request and conversation created |
| ADR-CRE-002 | Create duplicate request | 409 Conflict |
| ADR-CRE-003 | Create without company profile | 403 Forbidden |
| ADR-CRE-004 | Create without message | 400 Bad request |
| ADR-CRE-005 | Create with invalid student ID | 400 Bad request |
| ADR-CRE-006 | Create without authentication | 401 Unauthorized |
| ADR-CRE-007 | Create with empty message | 400 Bad request |
| ADR-CRE-008 | Create with long message | 201 Created |

##### 3.2 Update Request Status
**Test Cases**: 8 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| ADR-UPD-001 | Accept adoption request | Status updated to ACCEPTED |
| ADR-UPD-002 | Reject adoption request | Status updated to REJECTED |
| ADR-UPD-003 | Update non-existent request | 404 Not found |
| ADR-UPD-004 | Update without permission | 404 Not found |
| ADR-UPD-005 | Update with invalid status | 400 Bad request |
| ADR-UPD-006 | Update without authentication | 401 Unauthorized |
| ADR-UPD-007 | Update already processed | Status updated |
| ADR-UPD-008 | Update by wrong user | 404 Not found |

##### 3.3 List Requests
**Test Cases**: 7 tests
**Priority**: Medium

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| ADR-LST-001 | List sent requests (company) | Requests returned |
| ADR-LST-002 | List received requests (student) | Requests returned |
| ADR-LST-003 | List with no requests | Empty array |
| ADR-LST-004 | List without authentication | 401 Unauthorized |
| ADR-LST-005 | List with conversation data | Conversations included |
| ADR-LST-006 | List with proper ordering | Newest first |
| ADR-LST-007 | List with student skills | Skills included |

#### 4. Messaging System Tests (`message.test.ts`) - 31 Tests

##### 4.1 Conversation Management
**Test Cases**: 13 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| MSG-CON-001 | List conversations (student) | Conversations returned |
| MSG-CON-002 | List conversations (company) | Conversations returned |
| MSG-CON-003 | List with no conversations | Empty array |
| MSG-CON-004 | List without authentication | 401 Unauthorized |
| MSG-CON-005 | List with proper topic formatting | Adoption requests formatted |
| MSG-CON-006 | List ordered by recent activity | Most recent first |
| MSG-CON-007 | List with no messages | "No messages yet" shown |
| MSG-CON-008 | Get conversation messages | Messages returned |
| MSG-CON-009 | Get without permission | 403 Forbidden |
| MSG-CON-010 | Get non-existent conversation | 403 Forbidden |
| MSG-CON-011 | Get with adoption status | Status included |
| MSG-CON-012 | Get empty conversation | Empty messages array |
| MSG-CON-013 | Get with unauthorized user | 403 Forbidden |

##### 4.2 Message Creation
**Test Cases**: 18 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| MSG-SND-001 | Send message (student) | 201 Created |
| MSG-SND-002 | Send message (company) | 201 Created |
| MSG-SND-003 | Send to rejected conversation | 403 Forbidden |
| MSG-SND-004 | Send to accepted conversation | 201 Created |
| MSG-SND-005 | Send without permission | 403 Forbidden |
| MSG-SND-006 | Send to non-existent conversation | 404 Not found |
| MSG-SND-007 | Send without authentication | 401 Unauthorized |
| MSG-SND-008 | Send with empty content | 400 Bad request |
| MSG-SND-009 | Send with missing content | 400 Bad request |
| MSG-SND-010 | Send with valid content | Message created |
| MSG-SND-011 | Send with long content | 201 Created |
| MSG-SND-012 | Send with special characters | 201 Created |
| MSG-SND-013 | Send as unauthorized user | 403 Forbidden |
| MSG-SND-014 | Send with HTML content | Content sanitized |
| MSG-SND-015 | Send with script tags | Content sanitized |
| MSG-SND-016 | Send message ordering | Proper timestamp order |
| MSG-SND-017 | Send with emoji content | 201 Created |
| MSG-SND-018 | Send rate limiting | Rate limits enforced |

#### 5. Security Tests (`security.test.ts`) - 21 Tests

##### 5.1 Authentication Security
**Test Cases**: 8 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| SEC-AUTH-001 | JWT token validation | Invalid tokens rejected |
| SEC-AUTH-002 | Token expiration | Expired tokens rejected |
| SEC-AUTH-003 | Token tampering | Modified tokens rejected |
| SEC-AUTH-004 | Session hijacking prevention | Sessions properly isolated |
| SEC-AUTH-005 | Concurrent login protection | Multiple sessions handled |
| SEC-AUTH-006 | Password brute force | Rate limiting active |
| SEC-AUTH-007 | Account lockout | Accounts locked after attempts |
| SEC-AUTH-008 | Session timeout | Sessions expire properly |

##### 5.2 Input Validation Security
**Test Cases**: 8 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| SEC-INP-001 | SQL injection in login | Injection prevented |
| SEC-INP-002 | XSS in message content | Scripts sanitized |
| SEC-INP-003 | CSRF token validation | CSRF attacks prevented |
| SEC-INP-004 | File upload validation | Malicious files rejected |
| SEC-INP-005 | Request size limits | Large requests rejected |
| SEC-INP-006 | Header injection | Header attacks prevented |
| SEC-INP-007 | Path traversal | Directory traversal prevented |
| SEC-INP-008 | Command injection | Command injection prevented |

##### 5.3 Authorization Security
**Test Cases**: 5 tests
**Priority**: Critical

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| SEC-AUZ-001 | Role-based access control | Permissions enforced |
| SEC-AUZ-002 | Resource ownership | Only owners can modify |
| SEC-AUZ-003 | Privilege escalation | Escalation prevented |
| SEC-AUZ-004 | Cross-user data access | Access properly restricted |
| SEC-AUZ-005 | Admin panel access | Admin-only areas protected |

#### 6. Performance Tests (`performance.test.ts`) - 20 Tests

##### 6.1 Load Testing
**Test Cases**: 10 tests
**Priority**: High

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| PERF-LOAD-001 | 50 concurrent users login | < 2s response time |
| PERF-LOAD-002 | 100 concurrent API calls | < 1s response time |
| PERF-LOAD-003 | Database query optimization | < 500ms query time |
| PERF-LOAD-004 | Memory usage under load | < 512MB memory |
| PERF-LOAD-005 | CPU usage monitoring | < 80% CPU usage |
| PERF-LOAD-006 | Connection pool limits | Connections properly managed |
| PERF-LOAD-007 | Rate limiting effectiveness | Limits enforced |
| PERF-LOAD-008 | Cache performance | Cache hits > 80% |
| PERF-LOAD-009 | Database connection pooling | Connections reused |
| PERF-LOAD-010 | API response compression | Responses compressed |

##### 6.2 Stress Testing
**Test Cases**: 10 tests
**Priority**: Medium

| Test ID | Description | Expected Result |
|---------|-------------|-----------------|
| PERF-STR-001 | Maximum user capacity | System handles 500+ users |
| PERF-STR-002 | Database stress test | No data corruption |
| PERF-STR-003 | Memory leak detection | No memory leaks |
| PERF-STR-004 | Error handling under load | Graceful degradation |
| PERF-STR-005 | Recovery after overload | System recovers properly |
| PERF-STR-006 | File upload stress | Large files handled |
| PERF-STR-007 | Search performance | Search < 2s response |
| PERF-STR-008 | Report generation | Reports generated quickly |
| PERF-STR-009 | Concurrent database writes | No deadlocks |
| PERF-STR-010 | Network timeout handling | Timeouts handled gracefully |

### Test Execution Schedule

#### Automated Test Execution
- **Continuous Integration**: On every commit
- **Nightly Builds**: Full test suite + performance tests
- **Weekly**: Security scan + dependency audit
- **Release**: Complete test suite + manual verification

#### Manual Test Execution
- **Feature Testing**: During development
- **Integration Testing**: Before staging deployment
- **User Acceptance Testing**: Before production
- **Exploratory Testing**: Weekly sessions

### Test Data Management

#### Test Data Requirements
- **User Accounts**: 50+ test users (students/companies)
- **Job Offers**: 100+ test offers with various skills
- **Applications**: 200+ test applications
- **Messages**: 500+ test messages
- **Skills**: 50+ test skills

#### Data Generation Strategy
- **Faker.js** for realistic test data
- **Predefined scenarios** for specific test cases
- **Dynamic generation** for load testing
- **Cleanup procedures** after each test

### Defect Management

#### Severity Levels
1. **Critical**: System crashes, security vulnerabilities
2. **High**: Major feature not working, data loss
3. **Medium**: Feature partially working, workaround exists
4. **Low**: Minor UI issues, performance degradation

#### Resolution Timeframes
- **Critical**: 4 hours
- **High**: 24 hours
- **Medium**: 1 week
- **Low**: Next release cycle

### Test Reporting

#### Daily Reports
- Test execution results
- Coverage metrics
- Failed test analysis
- Performance benchmarks

#### Weekly Reports
- Coverage trend analysis
- Test suite performance
- Defect summary
- Quality metrics

#### Release Reports
- Complete test execution summary
- Coverage achievement
- Known issues and workarounds
- Performance validation

### Risk Assessment

#### High Risk Areas
1. **Authentication System** - Security critical
2. **Payment Processing** - Financial impact
3. **Data Migration** - Data integrity
4. **Third-party Integrations** - External dependencies

#### Mitigation Strategies
- **Comprehensive test coverage** for critical areas
- **Manual verification** for high-risk changes
- **Staged rollouts** for major updates
- **Rollback procedures** for failures

### Success Criteria

#### Test Completion Criteria
- **100% test execution** completion
- **Zero critical defects** remaining
- **Coverage thresholds** met (80%+ branch coverage)
- **Performance benchmarks** achieved

#### Quality Gates
- All tests passing
- No security vulnerabilities
- Performance within acceptable limits
- Documentation updated 

## Bug Identification, Tracking, and Correction

### 1. Introduction

This document outlines the formal plan for identifying, tracking, and correcting bugs within the "Adopte1Etudiant" application. The goal is to ensure a systematic approach to defect management, leading to improved software quality, stability, and a better user experience.

### 2. Bug Life Cycle

The bug life cycle defines the various states a bug goes through from discovery to closure:

1.  **New**: A bug is newly reported.
2.  **Open**: The bug has been reviewed and acknowledged.
3.  **Assigned**: The bug is assigned to a developer for fixing.
4.  **In Progress**: The developer is actively working on the fix.
5.  **Fixed**: The developer has implemented a fix and submitted the code.
6.  **To Be Verified (TBV)**: The fix is deployed to a testing environment, awaiting verification by QA.
7.  **Reopened**: The QA team has retested the bug and found it is not resolved.
8.  **Closed**: The bug has been verified by QA and confirmed as resolved.

### 3. Bug Severity and Priority

Bugs are classified by **Severity** (impact on the system) and **Priority** (urgency of fixing).

### 3.1. Severity Levels

*   **Critical**: Blocks major functionality, causes data loss, security vulnerability, or system crash. No workaround.
*   **High**: Major functionality is impaired, significant data corruption, or serious usability issue. Workaround exists but is inconvenient.
*   **Medium**: Minor functionality is affected, cosmetic issues, or performance degradation. Workaround is available.
*   **Low**: Trivial issues, typos, minor UI glitches. Does not impact functionality.

### 3.2. Priority Levels

*   **Immediate**: Must be fixed immediately (e.g., critical production issues).
*   **High**: Must be fixed in the current sprint/release.
*   **Medium**: Should be fixed in the next sprint/release.
*   **Low**: Can be fixed in a future release.

### 4. Bug Reporting Guidelines

All bugs will be reported in the designated issue tracking system (GitHub Issues) and must include the following information:

*   **Title**: Clear, concise summary of the bug.
*   **Description**: Detailed explanation of the bug, including what happened and what was expected.
*   **Steps to Reproduce**: Numbered list of steps to consistently reproduce the bug.
*   **Actual Result**: What currently happens.
*   **Expected Result**: What should happen.
*   **Severity**: (Critical, High, Medium, Low).
*   **Priority**: (Immediate, High, Medium, Low).
*   **Environment**: OS, browser, device, specific URL, etc.
*   **Screenshots/Videos**: Visual evidence of the bug (mandatory for UI/UX bugs).
*   **Reporter**: Name or username of the person who found the bug.
*   **Labels**: Relevant labels (e.g., `bug`, `api`, `web`, `frontend`, `backend`, `security`).

### 5. Bug Triage Process

Bugs will undergo a regular triage process, typically by the QA Lead and Product Owner:

1.  **Review**: Newly reported bugs are reviewed for clarity, completeness, and reproducibility.
2.  **Categorize**: Assign severity, priority, and relevant labels.
3.  **Assign**: Assign the bug to the appropriate development team member.
4.  **Prioritize**: Reorder based on severity, priority, and business impact.
5.  **Duplicate Check**: Mark as duplicate if an identical bug already exists.

### 6. Bug Fixing Process (Development Team)

1.  **Acknowledge**: Developer acknowledges the assigned bug.
2.  **Reproduce**: Developer attempts to reproduce the bug in a local development environment.
3.  **Analyze**: Identify the root cause of the bug.
4.  **Fix**: Implement the code fix, ensuring it doesn't introduce new issues.
5.  **Unit/Integration Tests**: Write or update unit and integration tests to cover the bug fix and prevent regressions.
6.  **Commit and Push**: Commit the fix to version control (e.g., Git) with a clear commit message referencing the bug ID.
7.  **Mark as Fixed**: Update the bug status in the tracking system to 'Fixed'.

### 7. Bug Verification and Closure (QA Team)

1.  **Retrieve Fixed Bug**: QA retrieves the fixed version of the application.
2.  **Retest**: Execute the original steps to reproduce the bug.
3.  **Verify Fix**: Confirm that the bug is no longer present and no new regressions are introduced.
4.  **Close Bug**: If the bug is verified, change its status to 'Closed' in the tracking system.
5.  **Reopen Bug**: If the bug persists or new issues arise, change status to 'Reopened' and provide detailed feedback to the developer.

### 8. Roles and Responsibilities

*   **End-Users/Testers**: Report bugs with comprehensive details.
*   **QA Lead/Team**: Triage bugs, verify fixes, manage the bug life cycle.
*   **Development Team**: Reproduce, analyze, and fix bugs; write tests for fixes.
*   **Product Owner**: Prioritize bugs based on business impact; make final decisions on bug resolution.

### 9. Tools and Systems

*   **Issue Tracking**: [GitHub Issues](https://github.com/HusseinDStudy/new_adopte1etudiant/issues) (Primary tool for bug reporting and tracking).
*   **Version Control**: Git/GitHub (for code management and linking bug fixes to commits).
*   **Communication**: Slack/Teams (for quick discussions and notifications related to critical bugs).
*   **Testing Frameworks**: Vitest (for unit/integration test coverage of fixes).

### 10. Reporting and Metrics

Regular reports will be generated to track bug resolution progress and identify trends:

*   **Bug Count by Status**: Number of new, open, fixed, and closed bugs.
*   **Bug Count by Severity/Priority**: Distribution of bugs across different classifications.
*   **Mean Time To Resolution (MTTR)**: Average time taken to fix and close bugs.
*   **Reopen Rate**: Percentage of bugs that are reopened after being marked as fixed.
*   **New Bugs vs. Fixed Bugs**: Trend analysis to understand the efficiency of the bug-fixing process.

---
