# Monitoring and Alerting (C4.1.2)

This guide outlines the monitoring and alerting strategies for the Adopte1Etudiant platform, focusing on API availability, database connectivity, and overall application health. It covers key performance indicators, tools, and incident response mechanisms.

## 1. Key Performance Indicators (KPIs)

To ensure optimal application performance and reliability, we track the following key indicators:

- **Availability**: The system's uptime, measured by successful `/health` endpoint responses.
- **Performance**: Latency (response times) for critical API endpoints, measured by P95 and P99 percentiles.
- **Error Rate**: Percentage of requests resulting in server errors (5xx status codes).
- **Resource Utilization**: CPU, memory, and disk I/O usage of application and database servers.

## 2. Monitoring Tools & Probes

We leverage a combination of automated probes and specialized tools for continuous monitoring:

### Automated Probes
- **Health Checks**: The `/health` endpoint on the API (`http://localhost:8080/health` or `https://your-domain.com/api/health`) provides a simple status check, returning `status=ok` on success.
- **Metrics Endpoint**: An admin-only `GET /metrics` endpoint provides detailed application metrics for Prometheus scraping (see section 3.2).

### Dedicated Monitoring Tools
- **Newman (Postman CLI)**: Used for functional API monitoring and asserting expected responses. The collection is located at `monitoring/postman-collection.json`.
- **Artillery**: Utilized for load testing and performance benchmarking to simulate user traffic and measure system behavior under stress. Configuration files are in `monitoring/artillery-config.yml`.
- **Detailed Setup**: For comprehensive instructions on installing and running these tools, refer to `monitoring/MONITORING_SETUP.md`.
- **CloudWatch Logs / Metrics**: For production environments, container logs are shipped to AWS CloudWatch, enabling centralized log management, metric extraction, and custom dashboards.

## 3. Metrics Collection and Visualization

### 3.1. API Metrics
The API collects various metrics to provide insights into its performance and health. These include:

- **Request Count**: Total number of incoming API requests.
- **Request Latency**: Time taken to process API requests.
- **Error Rates**: Number of requests resulting in HTTP 4xx or 5xx errors.
- **Database Query Times**: Performance of database interactions.
- **Active Connections**: Number of open database and API connections.

These metrics are exposed via the `/metrics` endpoint (admin only) and are designed to be scraped by monitoring systems like Prometheus.

### 3.2. CloudWatch Integration
In production, application logs and custom metrics are streamed to AWS CloudWatch, utilizing the `awslogs` driver. This integration requires the `AWS_REGION` environment variable to be configured.

This provides:

- **Centralized Logging**: All application and system logs are aggregated into specific log groups: `/adopte1etudiant/api` for the backend API and `/adopte1etudiant/web` for the frontend web application. This allows for easy searching and analysis.
- **Custom Metrics**: Key performance indicators (e.g., unique active users, offer creation rate) are extracted from logs and published as CloudWatch Metrics.
- **Dashboards**: Customizable dashboards visualize trends, anomalies, and overall system health over time.
- **Alarms**: Automated alarms trigger alerts based on predefined thresholds (e.g., high error rates, low availability).

## 4. Tracing and Correlation
To facilitate end-to-end request tracing and debugging across microservices, we implement `X-Request-Id` propagation:

- **Web Application**: The web app (client) automatically generates and adds an `X-Request-Id` header to every outgoing API call via `apps/web/src/services/apiClient.ts`.
- **API Backend**: The API receives this header and uses its value as the primary request identifier for all internal logging. This ID is also echoed back in the `x-request-id` response header.
- **Log Correlation**: All logs generated by the API in response to a specific request will include this `X-Request-Id`. In CloudWatch, this allows for easy filtering and correlation of all log entries related to a single user request, simplifying debugging and performance analysis.

## 5. Logging Strategy
Our logging strategy focuses on providing actionable insights for debugging, monitoring, and auditing:

- **Structured Logging**: Application logs are generated in a structured format (e.g., JSON) to facilitate automated parsing and analysis by logging tools like CloudWatch Logs.
- **Log Levels**: Standard log levels (DEBUG, INFO, WARN, ERROR, FATAL) are used to categorize log messages, allowing for dynamic adjustment of verbosity in different environments.
- **Sensitive Data Redaction**: Sensitive information (e.g., passwords, API keys) is automatically redacted from logs to maintain security and compliance.
- **Error Handler**: A centralized API error handler (`apps/api/src/middleware/errorHandler.ts`) ensures consistent error logging and response formatting.
- **Troubleshooting**: Detailed guidance on diagnosing issues can be found in `developer-guides/API-Guide.md#troubleshooting`.

## 6. Thresholds & Alerting

### 6.1. Defined Thresholds
- **Performance**: P95 < 500ms, P99 < 1000ms
- **Error Rate**: < 5%
- **Uptime**: â‰¥ 99.5% (target)
- Specific thresholds for load tests are defined in `monitoring/artillery-config.yml`.

### 6.2. Alerting Mechanism
Automated alerts are configured to notify the development and operations teams of critical issues:

- **Slack Notifications**: A dedicated Slack channel receives alerts for critical events (e.g., API downtime, high error rates, performance degradation). The notification script is `scripts/notify-slack.js` and requires the `SLACK_WEBHOOK_URL` secret.
- **CloudWatch Alarms**: CloudWatch Alarms are set up based on collected metrics to trigger notifications when predefined thresholds are breached.

### 6.3. Local Execution of Monitoring Tools
Developers can run monitoring tools locally for testing and debugging:

```bash
npm run monitor:api          # Run API functional tests using Newman
npm run monitor:performance  # Run performance tests using Artillery
npm run monitor:ci           # Runs both; sends Slack alert on failure if configured
```

### 6.4. Scheduled CI Monitoring (Optional)
For continuous health monitoring, a scheduled GitHub Actions workflow (`.github/workflows/monitoring.yml`) can be configured. It requires `MONITORING_BASE_URL` and `SLACK_WEBHOOK_URL` variables.

## 7. Improvement Recommendations

To further enhance observability and proactive issue detection, consider:
- Implementing a dedicated Application Performance Monitoring (APM) solution (e.g., Datadog, New Relic) for deeper insights into application traces and dependencies.
- Establishing a runbook for common alerts, detailing steps for investigation and resolution.
- Integrating real-time dashboards for operational metrics visible to the entire team.

---

